import logging
import os
from openai import OpenAI
from pinecone import Pinecone

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–ª—é—á–µ–π –∏ –º–æ–¥–µ–ª–µ–π
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
INDEX_NAME = os.getenv("INDEX_NAME", "YOUR_INDEX_NAME")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

EMBEDDING_MODEL = "text-embedding-ada-002"
LLM_MODEL = "gpt-4"

# –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–± –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Pinecone (v3.0.0+)
try:
    pc = Pinecone(api_key=PINECONE_API_KEY)
    index = pc.Index(INDEX_NAME)
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
    logging.info("‚úÖ Pinecone –∏ OpenAI –∫–ª–∏–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
except Exception as e:
    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
    pc = None
    index = None
    openai_client = None


def retrieve_relevant_posts(query: str, top_k: int = 5) -> str:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ Pinecone –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤."""
    if not index or not openai_client:
        logging.error("–ö–ª–∏–µ–Ω—Ç—ã –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return ""

    logging.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å: {query}")

    # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
    try:
        embedding_response = openai_client.embeddings.create(
            input=[query],
            model=EMBEDDING_MODEL
        )
        query_vector = embedding_response.data[0].embedding
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return ""

    logging.info("–≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")

    # 2. –ü–æ–∏—Å–∫ –≤ Pinecone –±–ª–∏–∂–∞–π—à–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
    try:
        results = index.query(
            vector=query_vector,
            top_k=top_k,
            include_metadata=True
        )
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Pinecone: {e}")
        return ""

    matches = results.get("matches", [])
    logging.info(f"–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(matches)}")

    # 3. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    context_pieces = []
    used_post_ids = set()

    for match in matches:
        metadata = match.get("metadata", {})
        post_id = metadata.get("post_id") or match.get("id")

        if post_id in used_post_ids:
            continue
        used_post_ids.add(post_id)

        date = metadata.get("date")
        location = metadata.get("location")
        text = metadata.get("text")

        piece_parts = []
        if date:
            piece_parts.append(f"–î–∞—Ç–∞: {date}.")
        if location:
            piece_parts.append(f"–õ–æ–∫–∞—Ü–∏—è: {location}.")
        if text:
            piece_parts.append(f"–ü–æ—Å—Ç: {text}")
        else:
            piece_parts.append("–ü–æ—Å—Ç: (—Ç–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")

        piece = " ".join(piece_parts)
        context_pieces.append(piece)

    context_text = "\n\n".join(context_pieces)
    logging.info(f"–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM (—Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(context_pieces)})")
    return context_text


def generate_answer_with_llm(question: str, context_text: str) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç prompt —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –≤–æ–ø—Ä–æ—Å–æ–º, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç LLM –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
    if not openai_client:
        return "–û—à–∏–±–∫–∞: OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"

    if not context_text:
        logging.info("–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–∞.")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —É –º–µ–Ω—è –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å."

    prompt = (
        "–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å. "
        "–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, —Å–∫–∞–∂–∏, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å.\n\n"
        f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n{context_text}\n\n"
        f"–í–æ–ø—Ä–æ—Å: {question}\n–û—Ç–≤–µ—Ç:"
    )

    try:
        response = openai_client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        answer = response.choices[0].message.content.strip()
        logging.info("–û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω.")
        return answer
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."


def answer_user_question(question: str) -> str:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –ø–æ—Å—Ç–∞–º –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å."""
    context = retrieve_relevant_posts(question)
    answer = generate_answer_with_llm(question, context)
    return answer


def test_connection():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å–µ—Ä–≤–∏—Å–∞–º"""
    print("üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π...")

    # –¢–µ—Å—Ç Pinecone
    if pc:
        try:
            stats = index.describe_index_stats()
            print(f"‚úÖ Pinecone –ø–æ–¥–∫–ª—é—á–µ–Ω. –í–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ: {stats.get('total_vector_count', 0)}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Pinecone: {e}")
    else:
        print("‚ùå Pinecone –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # –¢–µ—Å—Ç OpenAI
    if openai_client:
        try:
            test_embedding = openai_client.embeddings.create(
                input=["test"],
                model=EMBEDDING_MODEL
            )
            print(f"‚úÖ OpenAI –ø–æ–¥–∫–ª—é—á–µ–Ω. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {len(test_embedding.data[0].embedding)}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI: {e}")
    else:
        print("‚ùå OpenAI –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    test_connection()

    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –∫–ª—é—á–∞—Ö
    if PINECONE_API_KEY == "YOUR_PINECONE_API_KEY" or OPENAI_API_KEY == "YOUR_OPENAI_API_KEY":
        print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ó–∞–º–µ–Ω–∏—Ç–µ YOUR_PINECONE_API_KEY –∏ YOUR_OPENAI_API_KEY –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏!")
        print("–ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
        print("export PINECONE_API_KEY='your_key_here'")
        print("export OPENAI_API_KEY='your_key_here'")
        print("export INDEX_NAME='your_index_name'")
    else:
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        print("\nüöÄ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
        while True:
            try:
                user_question = input("\n–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞): ")
                if user_question.lower() in ['quit', 'exit', 'q']:
                    break
                answer = answer_user_question(user_question)
                print("\n–û—Ç–≤–µ—Ç:", answer)
            except KeyboardInterrupt:
                print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
